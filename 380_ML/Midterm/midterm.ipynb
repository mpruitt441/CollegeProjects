{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Midterm\n",
    "Due at Midnight on 4/2/19\n",
    "\n",
    "Please answer all questions in cells below.  \n",
    "\n",
    "If a question calls for a short answer style response, please answer in a Markdown cell.\n",
    "\n",
    "Unlike the projects and homeworks there is *no collaboration* allowed on this midterm.\n",
    "\n",
    "Also you may not use online resources to answer any of the questions, other than doing the most basic kind of research.  For example reading a Wikipedia article on VC dimension is fine.  But finding someone else's answer to the specific question asked is not.  \n",
    "\n",
    "Pasting code from anywhere is not allowed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Problem 1\n",
    "\n",
    "Please do Exercise 1.11 on page 25 of Learning From Data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "a) Can S produce a hypothesis that is guaranteed to perform better than random on any point outside D?\n",
    "- NO! There is no guarantee that S will perform better and tell us something CERTAIN about a point outside D. However, it is likely that it can tell us something LIKELY about a point outside D.\n",
    "\n",
    "\n",
    "b) Assume for the rest of the exercise that all the examples in D have y sub n = +1. Is it possible that the hypothesis that C produces turns out to be better than the hypothesis S produces?\n",
    "- Yes, it is possible because all the values are positive so the Crazy function may make judgements that align with all the values being positive.\n",
    "\n",
    "\n",
    "c) If p = .9, what is the probability that S will produce a better hypothesis than C?\n",
    "\n",
    "Given by the question, P[f(x) = +1] = p\n",
    "\n",
    "So, P[S = +1] = .9 (error rate .10)\n",
    "\n",
    "The data set is y sub n + 1 and the probability of S = +1 is .9 (with error rate .10)\n",
    "\n",
    "On the other hand, P[C = +1] is .5 because it can either be +1 or -1.\n",
    "\n",
    "Therefore: .9 > .5 (S>C), so S has a higher chance of producing a better hypothesis than C.\n",
    "\n",
    "d)Is there any value for p which it is more likely than not that C will produce a better hypothesis than S?\n",
    "\n",
    "- Yes, if p is less than .50, then C will produce a better hypothesis than S.\n",
    "\n",
    "So S < .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Problem 2\n",
    "\n",
    "Please do Exercise 1.12 on page 26 of Learning From Data.  Explain why the options you discarded are not accurate.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "a) After learning, you will provide her with a g that you will guarantee approximates f well out of sample\n",
    "- Since the data is COMPLETELY unknown, there is no guarantee that g wil approximate f well out of sample. The algorithm we code may reduce the in sample error by a lot, but run into many errors on the out of sample error. The algorithm may \"tune\" itself to the in sample error and not perform well out of sample. However, following the Hoeffding inequality, Ein can be the same as Eout if the data points she provides have anything to do with the target funciton or learning problem. This may make the out of sample error small and return a g that approximates f well.\n",
    "\n",
    "\n",
    "b) After learning, you will provide her with a g, and with high porbability the g which you will produce will approximate f well out of sample.\n",
    "- There is no guarantee that the g we produce will have a high probability of producing f well out of sample, since the target function is completely unknown. We may want a desired performance of having only 10% error, but this performance may be tuned only to the in sample error. Usually, in sample error will be less than out of sample error, but there is no guarantee that the algorithm we build will produce f well out of sample.\n",
    "\n",
    "c) One of two things will happen:\n",
    "- i) You will produce a hypothesis g;\n",
    "    - We will produce a hypothesis, but there is no guarantee that the hypothesis will have a high probability with approximating f well out of sample, since the function is completely unknown.\n",
    "- (ii) You will declare that you failed.\n",
    "    - This is a big possibility because the target function f is completely unknown and the algorithm we build may be tuned completely to the in sample, which may be outliers compared the the out sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Problem 3\n",
    "\n",
    "Please do Exercise 2.5 on page 56 of Learning From Data.  Be sure to show your calculations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "$M_{H}$(N) = N+1, $d_{vc}$ = 1, N = 100\n",
    "\n",
    "2.12 VC bound\n",
    "\n",
    "$M_{H}$(100) = 101\n",
    "\n",
    "$M_{H}$(2N) = 202\n",
    "\n",
    "so $E_{out}$(g) <= $E_{in}$(g) + $\\sqrt{\\frac{8}{N} *\\frac{4*(2*101)}{d}}$\n",
    "\n",
    "So:\n",
    ".1 = $\\sqrt{\\frac{8}{100}* ln(\\frac{4*202}{d})}$\n",
    "\n",
    "$.1^{2}$= ${\\frac{8}{100}* ln(\\frac{4*202}{d})}$\n",
    "\n",
    ".125 = ln($\\frac{808}{d})$\n",
    "\n",
    "$e^{.125}$ = $\\frac{808}{d}$\n",
    "\n",
    "d = $\\frac{808}{e^{.125}}$\n",
    "\n",
    "d = 713.0574\n",
    "\n",
    "Check:\n",
    "\n",
    "$\\sqrt{\\frac{8}{100}*ln(\\frac{4*202}{713.05})}$\n",
    "\n",
    "$\\sqrt{.08*ln(1.133)}$\n",
    "\n",
    "$\\sqrt{.08*.28517}$\n",
    "= .1\n",
    "\n",
    "\n",
    "$d_{vc}$ = 1 \n",
    "\n",
    "So:\n",
    "\n",
    "1 - .1\n",
    "= .90\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Problem 4\n",
    "\n",
    "Please do Exercise 2.6 on page 60 of Learning From Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "N = 600\n",
    "Subset/Train = 400\n",
    "Test = 200\n",
    "H = 1000\n",
    "\n",
    "We wish to estimate $E_{out}$.\n",
    "We have access to two estimates: $E_{in}$ and $E_{test}$\n",
    "\n",
    "\n",
    "a) Using a 5% error tolerance,which estimate has the higher error bar?\n",
    "\n",
    "Formula: $E_{out}$ <= $E_{in}$ + $\\sqrt{\\frac{8}{N} * ln(\\frac{4m_{h}(2N)}{d})}$\n",
    "\n",
    "Generalization formula for error bar: $\\sqrt{\\frac{1}{2N}*ln(\\frac{2M}{d})}$\n",
    "\n",
    "M = 1000 (size of H)\n",
    "\n",
    "d = .05\n",
    "\n",
    "for $E_{in}$\n",
    "N = 400\n",
    "\n",
    "\n",
    "$\\sqrt{\\frac{1}{800}*ln\\frac{2000}{.05}}$\n",
    "\n",
    "\n",
    "$\\sqrt{\\frac{1}{800}*ln(40000)}$ = .11509\n",
    "\n",
    "\n",
    "for $E_{test}$\n",
    "\n",
    "$\\sqrt{\\frac{1}{400}*ln(40000)}$ = .162762\n",
    "\n",
    "1 - .11509 = .88491\n",
    "\n",
    "1 - .162762 = .837238\n",
    "\n",
    "\n",
    "$E_{test}$ Error Bar = 1 - .84 = 16%\n",
    "\n",
    "$E_{in}$ Error Bar = 1-.89 = 11%\n",
    "\n",
    "So, $E_{test}$ has a higher error rate/bar than $E_{in}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "b) Is there any reason why you shoulnd't reserve even more examples for testing?\n",
    "- A reason why you shouldn't reserve more examples for testing is because if we reserve more, theres is only a small number of data points left to be our test set. Our algorithm could tune itself to the training set and not be a good example of the remaining data set. There wouldn't be enough data to be certain that our algorithm worked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Problem 5\n",
    "Please do Problem 2.8 on page 70 of Learning From Data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Which of the following are possible growth functions $m_{H}(N)$\n",
    "for some hypothesis set:\n",
    "\n",
    "answer is on pg 42\n",
    "\n",
    "The possible growth functions for $m_{h}(N)$ are:\n",
    "\n",
    "1 + N, $2^{N}$, $2^{(\\sqrt{N})}$, and $2^{(\\frac{N}{2})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Problem 6\n",
    "Please do Problem 2.1 on page 69 of Learning From Data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Set examples = to error and solve for N\n",
    "\n",
    "Formula:\n",
    "\n",
    "e(M,N,d) = $\\sqrt{\\frac{1}{2N} * ln(\\frac{2M}{d})}$\n",
    "\n",
    "### a) For M = 1, how many examples do we need to make e <= .005?\n",
    "\n",
    "M = 1\n",
    "\n",
    "d = 0.03\n",
    "\n",
    ".05 = $\\sqrt{\\frac{1}{2N} * ln(\\frac{2}{.03}}$\n",
    "\n",
    "$.05^{2}$ = $(\\sqrt{\\frac{1}{2N} * 4.21})^{2}$\n",
    "\n",
    ".0025 = $\\frac{1}{2N} * 4.21$\n",
    "\n",
    ".005N = 4.21\n",
    "\n",
    "N = 842 \n",
    "\n",
    "### b) for M = 100, how many examples do we need to make e <= .005?\n",
    "\n",
    "M = 100\n",
    "\n",
    "d = 0.03\n",
    "\n",
    ".05 = $\\sqrt{\\frac{1}{2N} * ln(\\frac{200}{.03}}$\n",
    "\n",
    "$.05^{2}$ = $(\\sqrt{\\frac{1}{2N} * ln 6666.67})^{2}$\n",
    "\n",
    ".0025 = $\\frac{1}{2N} * 8.81$\n",
    "\n",
    ".005N = 8.81\n",
    "\n",
    "\n",
    "### c) for M == 10,000, how many examples do we need to make e <= .005?\n",
    "\n",
    "M = 10000\n",
    "\n",
    "d = 0.03\n",
    "\n",
    ".05 = $\\sqrt{\\frac{1}{2N} * ln(\\frac{20,000}{.03}}$\n",
    "\n",
    "$.05^{2}$ = $(\\sqrt{\\frac{1}{2N} * ln 666666.67})^{2}$\n",
    "\n",
    ".0025 = $\\frac{1}{2N} * 13.41$\n",
    "\n",
    ".005N = 13.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Problem 7\n",
    "\n",
    "Suppose $\\mathcal{X} = \\{1,2,3,\\ldots,99,100\\}$.  For any subset $k \\subseteq \\mathcal{X}$ define $h_k: \\mathcal{X} \\rightarrow \\{1,-1\\}$ by \n",
    "\n",
    " \\begin{equation}\n",
    "h_k(x) = \\begin{cases}\n",
    "      +1 & \\text{ if } x\\in k \\\\\n",
    "      -1        & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "  \n",
    "Suppose $\\mathcal{H} = \\{h_k: k \\subseteq \\mathcal{X}\\text{ and } |k|\\geq 90\\}$.  What is the VC dimension of $\\mathcal{H}$? \n",
    "\n",
    "Hints:\n",
    "1. Start by trying to shatter some simple sets like $\\{1\\}$, $\\{1,2\\}$ and $\\{1,2,3\\}$ just to get a feel for the problem. \n",
    "1. To show that the VC dimension is $\\geq d$, exhibit a shattered set of size $d$.\n",
    "1. To show that the VC dimension is $\\leq d$, argue that no subset of size $d+1$ can be shattered.\n",
    "1. Think about $\\mathcal{J} = \\{h_k: k \\subseteq \\mathcal{X}\\text{ and } |k| \\leq 10\\}$. Do you find this one simpler to analyze?  What is the connection between $\\mathcal{H}$ and $\\mathcal{J}$ in terms of shattered sets? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Def: The VC Dimesion of H is the size of the largest shattered set.\n",
    "= The max N such at $m_{h}(N)$ = $2^{n}$\n",
    "\n",
    "We can shatter up to 4 points with a rectangle enclosing all the points if k = {1,2,3,4}.\n",
    "\n",
    "Points between 1 and 3 can be shattered using a line.\n",
    "\n",
    "With shapes, we can shatter all up to $2^{n}$\n",
    "\n",
    "So, since the max the cardinality of k is 90:\n",
    "\n",
    "$2^{6}$ = 64\n",
    "\n",
    "where |k| = 6\n",
    "\n",
    "But, $2^{7}$ = 128\n",
    "\n",
    "where |k| = 7\n",
    "\n",
    "therefore, the VC dimension of H is 6.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda 5)",
   "env": {
    "LD_LIBRARY_PATH": "/ext/anaconda5/lib",
    "PYTHONHOME": "/ext/anaconda5/lib/python3.5",
    "PYTHONPATH": "/ext/anaconda5/lib/python3.5:/ext/anaconda5/lib/python3.5/site-packages"
   },
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python/R distribution for data science",
     "priority": 5,
     "url": "https://www.anaconda.com/distribution/"
    }
   },
   "name": "anaconda5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}